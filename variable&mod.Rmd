---
title: "Models for preliminary report"
author: "Benedicte"
date: "14/07/2020"
output: pdf_document

---

```{r message=FALSE, warning=FALSE}
#Don't remove my libraries, I use them all.
library(tidyr)
library(caret)
library(dplyr)
library(lubridate)
library(corrplot)
library("pROC")
library(ggplot2)
library(RColorBrewer)
library(kableExtra)
library("arm")
library("car")
library("jtools")
library(pls)
library(glmnet)
library(MASS)
library("leaps")
```

#Read data 
```{r warning=FALSE}
kickstarter_min <- readRDS("/Users/benedicte/Downloads/final_clean_kickstarter.rds")

#These variables are only dropped temprarily. While I am trying to find the variables that caused the error in best subset, lasso and pcl. I talked to Steve about it and he said this was smart to do while I was looking for the variable creating the complications. 
kickstarter_min$cat_child <- NULL
kickstarter_min$city <- NULL
kickstarter_min$blurb <- NULL
kickstarter_min$country_displayable_name <- NULL 
kickstarter_min$country <- NULL 
kickstarter_min$name <- NULL

str(kickstarter_min)
 
```




#change country to continent 
```{r warning=FALSE}
#This changes countries over to continent so we have less levles and still have a variable which puts the area of the project. I have cheked the code with Steve and he said it was clean and easy to read so it was good. 
cntnt_Europe = c("DK","AT", "BE", "CH","DE","ES", "FR", "GB","IE", "IT","LU", "NL","NO","SE")
cntnt_Asia = c("HK","JP","SG")
cntnt_NA = c("US","CA")
cntnt_SA = c("MX")
cntnt_Pacific = c("NZ","NZ")
#cntnt_NAmer =

eurpn <- kickstarter_min$country %in% cntnt_Europe
asian <- kickstarter_min$country %in% cntnt_Asia  
na <- kickstarter_min$country %in% cntnt_NA
sa <- kickstarter_min$country %in% cntnt_SA
pacific <- kickstarter_min$country %in% cntnt_Pacific

kickstarter_min$continent = "ph"
kickstarter_min$continent[eurpn] <- "Europe"
kickstarter_min$continent[asian] <- "Asia"
kickstarter_min$continent[na] <- "NorthAmerica"
kickstarter_min$continent[sa] <- "SouthAmerica"
kickstarter_min$continent[pacific] <- "Pacific"
```



#Split into train and test 
```{r}
#For the sample of the date when attempting varibale selection.
sub_kickstarter <- kickstarter_min[sample(nrow(kickstarter_min), 1000), ]

set.seed(456) 
SplitIndex <- sample(x = c("Train", "Test"), replace = T, prob = c(0.7,0.3), 
                     size = nrow(sub_kickstarter))

#Subset data into a train and test set based on the SplitIndex vector
traindata <- sub_kickstarter[SplitIndex == "Train", ]
testdata <- sub_kickstarter[SplitIndex == "Test", ]
```


#Variable selection 
##Best subset 
Since it gave computional errors when attempting best subset, stepwise, lasso and pcl even with variables with many levels dropped and a smaller sample it was determined to attempt variable selection by running it on less variables. 
Based on this it seems like blurb, blurb lengt, county, country displayable name, number of days seems to make no impact on the dependent variable. 
```{r, eval= FALSE}
#nXvars <- ncol(traindata) - 1
#regfit.best <- regsubsets(goal_ratio ~. , data = traindata, nvmax = nXvars, really.big = T)
#summary(regfit.best)


nXvars <- ncol(traindata[,-c(2,5,11,13)]) - 1
nXvars = 15
names(traindata) # goal_ratio is col 15
#id is 
cbind(names(traindata), 1:18) #exclude: 2,5,7,8,9,
regfit.best <- regsubsets(goal_ratio ~. , data = traindata[,-c(2,5,11,13)][, 5:13], nvmax = nXvars, really.big = T)
summary(regfit.best)


```

```{r, eval= FALSE}
which.max(summary(regfit.best)$adjr2)
which.min(summary(regfit.best)$cp)
which.min(summary(regfit.best)$bic)
```


```{r, eval= FALSE}
glm_model <- lm(pledged_log ~., data = traindata)
ols_step_all_possible(glm_model)

```


##PLS
```{r, eval = FALSE}
pcrPledged <- pcr(goal_ratio ~. , data = traindata[,-c(2,5,11,13)][, 5:13], validation="CV",scale=T)
pcrPledged$loadings
```


##Lasso 
```{r, eval =FALSE}
set.seed(456)
lasso <- glmnet(model.matrix(goal_ratio ~. , data = traindata[,-c(2,5,11,13)][, 5:13])[, -1],
  traindata$goal_ratio,
  alpha = 1, k = 2, labmda = 10^seq(10, -2, length = 1000)
)
plot(lasso)
```

#Regression model 
##Baseline from best subset 
```{r}
glm_baseline1 <- glm(goal_ratio ~ backers_count + 
                      cat_parent + continent + month + 
                      goal_log + goal +staff_pick + name_length + pledged_log,
                     data = traindata)
```

```{r}
identity(glm_baseline1)
```


##Baseline with pledged_log as dependent variable 
```{r}
glm_baseline <- glm(pledged_log ~ backers_count + 
                      cat_parent + continent + month + 
                      goal_log + staff_pick  + 
                      blurb_length + name_length , data = traindata)
```

```{r}
identity(glm_baseline)
```



#Evaluate regression model 
##RMSE
```{r}
postResample(glm_baseline$fitted.values, glm_baseline$data$pledged_log)
```


```{r}
postResample(glm_baseline1$fitted.values, glm_baseline1$data$goal_ratio)

#options(scipen = 999)
#get rid off e

```


##Residual plot 
```{r}
plot(glm_baseline, col=c("royalblue4"))
```


```{r}
plot(glm_baseline1, col=c("royalblue4"))
```


```{r}
plot_summs(glm_baseline, scale = TRUE, plot.distributions = TRUE, inner_ci_level = .95)
```


#Binominal model 
##Baseline from best subset


##Baseline model with goal  
```{r}
binominal_baseline <- glm(target ~ backers_count +
                            cat_parent + country +
                            month + goal + staff_pick  +
                            number_of_days + blurb_length +
                            name_length , data = traindata, family = binomial)
```

##Baseline model with goal_log

##Baseline model with goal_ratio 



#Evaluate Binominal model 
##Model accuracy, precision, sensitivity, 
```{r warning=FALSE}
confusionStats_df <- function(df,target){ # is as.character needed?
  cm <- confusionMatrix(table(Actual = df[[target]],Predicted = df$ClassPredict))
  return(data.frame(cbind(t(cm$overall),t(cm$byClass))))
}

predictLog <- function(df,log, thresh=0.5, t=T, f=F){
    
  p           <- predict(object = log, newdata = df,
                            type = "response",se.fit=T)
  df$fit      <- p$fit
  df$se.fit   <- p$se.fit
  df$logits   <- predict(object = log, newdata = df)
  df$ClassPredict <- ifelse(df$fit > thresh, t, f)
  return(df)
}

results <- predictLog(testdata, binominal_baseline, t="successful", f="failed")

results$ClassPredict <- as.factor(results$ClassPredict)

confusionStats_df(results,"target")[c("Accuracy","Sensitivity","Specificity","Precision")]

kable(confusionStats_df(results,"target")[c("Accuracy","Sensitivity","Specificity","Precision")]* 100, digits = 2, caption = "Model performance in percentage", booktabs = TRUE) %>%
  kable_styling(font_size = 10, full_width = F)%>%
  kable_styling(bootstrap_options = c("striped", "scale_down", "hover", "condensed")) 



```




##ROC 
```{r warning=FALSE}
plot.roc(results$target,results$fit, col = "royalblue4", backgroundcol = "lightskyblue",
         main = "Binominal baseline model", print.auc = TRUE)
```

##Residual plot 

```{r}
binnedplot(results$fit, as.numeric(results$target) - as.numeric(results$ClassPredict), col.pts = "royalblue4", col.int = "lightskyblue")
```


